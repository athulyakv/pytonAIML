{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a5619a-a03e-4533-9cec-28b8daea86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded:\n",
      "   EMPLOYEE_ID FIRST_NAME  LAST_NAME     EMAIL  PHONE_NUMBER  HIRE_DATE  \\\n",
      "0          198     Donald   OConnell  DOCONNEL  650.507.9833  21-Jun-07   \n",
      "1          199    Douglas      Grant    DGRANT  650.507.9844  13-Jan-08   \n",
      "2          200   Jennifer     Whalen   JWHALEN  515.123.4444  17-Sep-03   \n",
      "3          201    Michael  Hartstein  MHARTSTE  515.123.5555  17-Feb-04   \n",
      "4          202        Pat        Fay      PFAY  603.123.6666  17-Aug-05   \n",
      "\n",
      "     JOB_ID  SALARY  \n",
      "0  SH_CLERK    2600  \n",
      "1  SH_CLERK    2600  \n",
      "2   AD_ASST    4400  \n",
      "3    MK_MAN   13000  \n",
      "4    MK_REP    6000  \n",
      "['EMPLOYEE_ID', 'FIRST_NAME', 'LAST_NAME', 'EMAIL', 'PHONE_NUMBER', 'HIRE_DATE', 'JOB_ID', 'SALARY']\n",
      "['employee_id', 'first_name', 'last_name', 'email', 'phone_number', 'hire_date', 'job_id', 'salary']\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Set up basic logging\n",
    "logging.basicConfig(\n",
    " filename='etl_log.txt',\n",
    " level=logging.INFO,\n",
    " format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import datetime\n",
    "csv_file_path = 'D:\\\\Downloads\\\\employees1.csv'\n",
    "df = pd.read_csv('D:\\\\Downloads\\\\employees1.csv')\n",
    "print(\"Raw data loaded:\")\n",
    "print(df.head())\n",
    "print(df.columns.tolist())\n",
    "logging.info(\"CSV loaded successfully.\")\n",
    "# Handle missing values\n",
    "df.fillna({\n",
    " 'EMAIL': 'not_provided@example.com',\n",
    " 'PHONE_NUMBER': '0000000000',\n",
    " 'HIRE_DATE': '01-Jan-00',\n",
    " 'SALARY': 0\n",
    "}, inplace=True)\n",
    "# Standardize column names (optional)\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "print(df.columns.tolist())\n",
    "# Convert hire_date from 'dd-MMM-yy' to 'YYYY-MM-DD'\n",
    "df['hire_date'] = pd.to_datetime(df['hire_date'], format='%d-%b-%y', \n",
    "errors='coerce')\n",
    "# Replace invalid dates with a default\n",
    "df['hire_date'] = df['hire_date'].fillna(pd.to_datetime('2000-01-01'))\n",
    "# Replace non-numeric salaries with 0\n",
    "df['salary'] = pd.to_numeric(df['salary'], errors='coerce').fillna(0).astype(int)\n",
    "logging.info(\"Data cleaning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1ed8c5-f770-425d-b1c2-a1e4ff5745f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ETL.ipynb to script\n",
      "[NbConvertApp] Writing 117 bytes to ETL.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "get_ipython().system('jupyter nbconvert --to script ETL.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae67538-b7f4-48f8-983d-a3cdc50723b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
